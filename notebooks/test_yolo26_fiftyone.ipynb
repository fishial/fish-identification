{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO26 Fish Detection - FiftyOne Integration\n",
    "\n",
    "This notebook is designed to test YOLO26 using FiftyOne datasets.\n",
    "\n",
    "## Capabilities:\n",
    "- ‚úÖ Load data from FiftyOne\n",
    "- ‚úÖ Run YOLO26 inference on test images\n",
    "- ‚úÖ Visualize results with bounding boxes\n",
    "- ‚úÖ Compare against FiftyOne ground truth\n",
    "- ‚úÖ Save predictions back to FiftyOne\n",
    "- ‚úÖ Interactive visualization in the FiftyOne App\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports & Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "from fiftyone import ViewField as F\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure matplotlib\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (20, 12)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "print(\"‚úÖ Libraries imported\")\n",
    "print(f\"FiftyOne version: {fo.__version__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label used for all ground truth and predictions\n",
    "DETECTION_LABEL = \"Fish\"\n",
    "\n",
    "#YOLO26 Medium 371 ms ¬± 1.1 ms per loop (mean ¬± std. dev. of 7 runs, 1 loop each)\n",
    "#YOLO26 Nano  60.7 ms ¬± 1.05 ms per loop (mean ¬± std. dev. of 7 runs, 10 loops each)\n",
    "#YOLO10 Nanon 173 ms ¬± 1.3 ms per loop (mean ¬± std. dev. of 7 runs, 1 loop each)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============== CONFIGURATION ==============\n",
    "\n",
    "# FiftyOne dataset\n",
    "FIFTYONE_DATASET_NAME = \"segmentation_dataset_v0.10\"\n",
    "\n",
    "# Path to the trained model\n",
    "MODEL_PATH = \"\"\n",
    "# Detection parameters\n",
    "CONFIDENCE_THRESHOLD = 0.25\n",
    "IOU_THRESHOLD = 0.45\n",
    "IMG_SIZE = 640\n",
    "\n",
    "# Field name to store predictions in FiftyOne\n",
    "PREDICTIONS_FIELD = \"xyz\"\n",
    "\n",
    "# Field containing ground truth (Polylines segmentation)\n",
    "GT_FIELD = 'General body shape'\n",
    "\n",
    "# Visualization settings\n",
    "BOX_THICKNESS = 3\n",
    "FONT_SCALE = 1.0\n",
    "\n",
    "print(\"‚úÖ Configuration loaded\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load FiftyOne Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "print(f\"Loading FiftyOne dataset: {FIFTYONE_DATASET_NAME}\")\n",
    "dataset = fo.load_dataset(FIFTYONE_DATASET_NAME)\n",
    "\n",
    "print(f\"\\n‚úÖ Dataset loaded\")\n",
    "print(f\"Total samples: {len(dataset)}\")\n",
    "print(f\"Media type: {dataset.media_type}\")\n",
    "\n",
    "# Check for available splits\n",
    "print(f\"\\nAvailable tags: {dataset.count_values('tags')}\")\n",
    "\n",
    "# Retrieve the test split\n",
    "test_view = dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load YOLO26 Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Loading model: {MODEL_PATH}\")\n",
    "model = YOLO(MODEL_PATH)\n",
    "# model.cpu()\n",
    "print(f\"\\n‚úÖ Model loaded successfully!\")\n",
    "print(f\"Number of classes: {len(model.names)}\")\n",
    "print(f\"Classes: {model.names}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the first sample from the test view\n",
    "sample = test_view.first()\n",
    "\n",
    "print(f\"Processing sample: {sample.id}\")\n",
    "print(f\"File: {sample.filepath}\")\n",
    "\n",
    "# Run detection\n",
    "%timeit model.predict(source=sample.filepath, conf=CONFIDENCE_THRESHOLD, iou=IOU_THRESHOLD, imgsz=IMG_SIZE, verbose=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualization Helper Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_mask_alpha(image, mask, color=(0, 255, 0), alpha=0.4):\n",
    "    \"\"\"\n",
    "    Applies a binary mask to the image with alpha blending.\n",
    "    The mask is automatically resized when the dimensions do not match.\n",
    "    \"\"\"\n",
    "    output = image.copy()\n",
    "\n",
    "    # Convert mask to uint8 and binarize\n",
    "    mask = mask.astype(np.uint8)\n",
    "    mask[mask > 0] = 1\n",
    "\n",
    "    # Resize if dimensions do not match the image\n",
    "    if mask.shape[:2] != image.shape[:2]:\n",
    "        mask = cv2.resize(mask, (image.shape[1], image.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    mask_bool = mask.astype(bool)\n",
    "\n",
    "    colored_mask = np.zeros_like(image, dtype=np.uint8)\n",
    "    colored_mask[mask_bool] = color\n",
    "\n",
    "    output[mask_bool] = cv2.addWeighted(\n",
    "        image[mask_bool],\n",
    "        1 - alpha,\n",
    "        colored_mask[mask_bool],\n",
    "        alpha,\n",
    "        0\n",
    "    )\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def draw_boxes_on_image(image, boxes, color=(0, 255, 0), thickness=BOX_THICKNESS, font_scale=FONT_SCALE, label_prefix=\"\"):\n",
    "    \"\"\"Draws bounding boxes and labels for a list of detections.\n",
    "    \"\"\"\n",
    "    output = image.copy()\n",
    "    h, w = output.shape[:2]\n",
    "\n",
    "    for detection in boxes:\n",
    "        bbox = detection.get(\"bbox\")\n",
    "        if not bbox or len(bbox) != 4:\n",
    "            continue\n",
    "\n",
    "        x, y, box_w, box_h = bbox\n",
    "        normalized = all(0 <= val <= 1 for val in (x, y, box_w, box_h))\n",
    "\n",
    "        if normalized:\n",
    "            x1 = int(round(x * w))\n",
    "            y1 = int(round(y * h))\n",
    "            x2 = int(round((x + box_w) * w))\n",
    "            y2 = int(round((y + box_h) * h))\n",
    "        else:\n",
    "            x1 = int(round(x))\n",
    "            y1 = int(round(y))\n",
    "            x2 = int(round(x + box_w))\n",
    "            y2 = int(round(y + box_h))\n",
    "\n",
    "        x1, y1 = max(0, x1), max(0, y1)\n",
    "        x2, y2 = min(w - 1, x2), min(h - 1, y2)\n",
    "\n",
    "        cv2.rectangle(output, (x1, y1), (x2, y2), color, thickness)\n",
    "\n",
    "        label = detection.get(\"label\")\n",
    "        confidence = detection.get(\"confidence\")\n",
    "\n",
    "        text_parts = []\n",
    "        if label:\n",
    "            text_parts.append(f\"{label_prefix}{label}\")\n",
    "        elif label_prefix:\n",
    "            text_parts.append(label_prefix.strip())\n",
    "\n",
    "        if confidence is not None:\n",
    "            text_parts.append(f\"{confidence:.2f}\")\n",
    "\n",
    "        if text_parts:\n",
    "            text = \" \".join(text_parts)\n",
    "            text_size, baseline = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, font_scale, 1)\n",
    "            text_width, text_height = text_size\n",
    "            text_origin = (x1, max(0, y1 - text_height - baseline - 4))\n",
    "            text_bg_top_left = (text_origin[0], text_origin[1])\n",
    "            text_bg_bottom_right = (\n",
    "                text_origin[0] + text_width + 4,\n",
    "                text_origin[1] + text_height + baseline + 4,\n",
    "            )\n",
    "\n",
    "            cv2.rectangle(output, text_bg_top_left, text_bg_bottom_right, color, cv2.FILLED)\n",
    "            cv2.putText(\n",
    "                output,\n",
    "                text,\n",
    "                (text_origin[0] + 2, text_origin[1] + text_height + baseline),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                font_scale,\n",
    "                (255, 255, 255),\n",
    "                1,\n",
    "                cv2.LINE_AA,\n",
    "            )\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def visualize_sample_with_predictions(sample, predictions, show_ground_truth=True):\n",
    "    \"\"\"\n",
    "    Visualizes a sample with YOLO predictions (boxes + masks) and optional ground truth.\n",
    "    \"\"\"\n",
    "    image = cv2.imread(sample.filepath)\n",
    "    if image is None:\n",
    "        print(f\"‚ö†Ô∏è Failed to load image: {sample.filepath}\")\n",
    "        return\n",
    "\n",
    "    h, w = image.shape[:2]\n",
    "    result = predictions[0]\n",
    "\n",
    "    # ----------------------------\n",
    "    # YOLO predictions\n",
    "    # ----------------------------\n",
    "    pred_boxes = []\n",
    "    pred_masks = []\n",
    "\n",
    "    has_masks = result.masks is not None\n",
    "    img_preds = image.copy()\n",
    "    \n",
    "    for i, box in enumerate(result.boxes):\n",
    "        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "        conf = float(box.conf[0])\n",
    "\n",
    "        if conf < CONFIDENCE_THRESHOLD:\n",
    "            continue\n",
    "\n",
    "        cls = int(box.cls[0])\n",
    "\n",
    "        pred_boxes.append({\n",
    "            'bbox': [x1 / w, y1 / h, (x2 - x1) / w, (y2 - y1) / h],\n",
    "            'label': model.names[cls],\n",
    "            'confidence': conf\n",
    "        })\n",
    "\n",
    "        if has_masks and hasattr(result.masks, \"xy\"):\n",
    "            pred_masks.append(result.masks.data[i].cpu().numpy())\n",
    "            for polygon in result.masks.xy:  # list of polygons\n",
    "                # polygon.shape = [num_points, 2]\n",
    "                pts = np.array(polygon, np.int32)\n",
    "                pts = pts.reshape((-1, 1, 2))  # needed for cv2.polylines\n",
    "                cv2.polylines(img_preds, [pts], isClosed=True, color=POLYGON_COLOR, thickness=6)\n",
    "\n",
    "\n",
    "    # ----------------------------\n",
    "    # Ground truth\n",
    "    # ----------------------------\n",
    "    gt_boxes = []\n",
    "    if show_ground_truth and GT_FIELD in sample.field_names and sample[GT_FIELD]:\n",
    "        for polyline in sample[GT_FIELD].polylines:\n",
    "            all_points = [p for segment in polyline.points for p in segment]\n",
    "            if all_points:\n",
    "                xs = [p[0] for p in all_points]\n",
    "                ys = [p[1] for p in all_points]\n",
    "                x_min, x_max = min(xs), max(xs)\n",
    "                y_min, y_max = min(ys), max(ys)\n",
    "                gt_boxes.append({\n",
    "                    'bbox': [x_min, y_min, x_max - x_min, y_max - y_min],\n",
    "                    'label': polyline.label if hasattr(polyline, 'label') else 'fish',\n",
    "                })\n",
    "\n",
    "    # ----------------------------\n",
    "    # Visualization\n",
    "    # ----------------------------\n",
    "    num_plots = 3 if show_ground_truth and gt_boxes else 2\n",
    "    fig, axes = plt.subplots(1, num_plots, figsize=(20, 8))\n",
    "    if num_plots == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    # Original\n",
    "    axes[0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    axes[0].set_title(\"Original\", fontsize=16, fontweight=\"bold\")\n",
    "    axes[0].axis(\"off\")\n",
    "\n",
    "    # Predictions (masks -> boxes)\n",
    "    \n",
    "\n",
    "    for mask in pred_masks:\n",
    "        img_preds = apply_mask_alpha(\n",
    "            img_preds,\n",
    "            mask,\n",
    "            color=MASK_COLOR,\n",
    "            alpha=MASK_ALPHA\n",
    "        )\n",
    "\n",
    "    img_preds = draw_boxes_on_image(\n",
    "        img_preds,\n",
    "        pred_boxes,\n",
    "        color=MASK_COLOR,\n",
    "        label_prefix=\"\"\n",
    "    )\n",
    "\n",
    "    axes[1].imshow(cv2.cvtColor(img_preds, cv2.COLOR_BGR2RGB))\n",
    "    axes[1].set_title(\n",
    "        f\"YOLO Predictions ({len(pred_boxes)})\",\n",
    "        fontsize=16,\n",
    "        fontweight=\"bold\",\n",
    "        color=\"green\"\n",
    "    )\n",
    "    axes[1].axis(\"off\")\n",
    "\n",
    "    # Ground truth\n",
    "    if show_ground_truth and gt_boxes:\n",
    "        img_gt = draw_boxes_on_image(\n",
    "            image,\n",
    "            gt_boxes,\n",
    "            color=(0, 0, 255),\n",
    "            label_prefix=\"GT: \"\n",
    "        )\n",
    "        axes[2].imshow(cv2.cvtColor(img_gt, cv2.COLOR_BGR2RGB))\n",
    "        axes[2].set_title(\n",
    "            f\"Ground Truth ({len(gt_boxes)})\",\n",
    "            fontsize=16,\n",
    "            fontweight=\"bold\",\n",
    "            color=\"red\"\n",
    "        )\n",
    "        axes[2].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # ----------------------------\n",
    "    # Stats\n",
    "    # ----------------------------\n",
    "    print(f\"\\n{'=' * 70}\")\n",
    "    print(f\"Sample ID: {sample.id}\")\n",
    "    print(f\"File: {Path(sample.filepath).name}\")\n",
    "    print(f\"Size: {w}x{h}\")\n",
    "    print(f\"Predicted: {len(pred_boxes)} objects\")\n",
    "    if gt_boxes:\n",
    "        print(f\"Ground truth: {len(gt_boxes)} objects\")\n",
    "    print(f\"{'=' * 70}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Single Image Test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Multiple Image Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MASK_COLOR = (0, 255, 0)   # BGR\n",
    "POLYGON_COLOR = (255, 255, 0)   # BGR\n",
    "MASK_ALPHA = 0.4\n",
    "\n",
    "# Take a few random samples\n",
    "NUM_SAMPLES = 1000\n",
    "samples = test_view.take(NUM_SAMPLES)\n",
    "\n",
    "print(f\"Processing {len(samples)} images\\n\")\n",
    "\n",
    "for sample in samples:\n",
    "    if len(sample['General body shape']['polylines']) > 1:\n",
    "        # Run detection\n",
    "        results = model.predict(\n",
    "            source=sample.filepath,\n",
    "            conf=CONFIDENCE_THRESHOLD,\n",
    "            iou=IOU_THRESHOLD,\n",
    "            imgsz=IMG_SIZE,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        # Visualization\n",
    "        visualize_sample_with_predictions(sample, results, show_ground_truth=True)\n",
    "        print(\"\\n\" + \"=\"*80 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Run Detection on the Full Test Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "PREDICTIONS_FIELD = ''\n",
    "\n",
    "print(f\"Running detection on {len(test_view)} images...\")\n",
    "print(f\"Results will be stored in field: '{PREDICTIONS_FIELD}'\\n\")\n",
    "\n",
    "for i, sample in tqdm(enumerate(test_view), total=len(test_view)):\n",
    "    \n",
    "    # Run YOLO detection\n",
    "    results = model.predict(\n",
    "        source=sample.filepath,\n",
    "        conf=CONFIDENCE_THRESHOLD,\n",
    "        iou=IOU_THRESHOLD,\n",
    "        imgsz=IMG_SIZE,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    detections = []\n",
    "    polygons = []\n",
    "    img = cv2.imread(sample.filepath)\n",
    "    h, w = img.shape[:2]\n",
    "    \n",
    "    result = results[0]\n",
    "    \n",
    "    # ----------------------------\n",
    "    # Process bounding boxes\n",
    "    # ----------------------------\n",
    "    for box in result.boxes:\n",
    "        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "        conf = float(box.conf[0])\n",
    "        if conf < CONFIDENCE_THRESHOLD:\n",
    "            continue\n",
    "        cls = int(box.cls[0])\n",
    "        \n",
    "        det = fo.Detection(\n",
    "            label=DETECTION_LABEL,\n",
    "            bounding_box=[x1/w, y1/h, (x2-x1)/w, (y2-y1)/h],\n",
    "            confidence=conf\n",
    "        )\n",
    "        detections.append(det)\n",
    "    \n",
    "    # ----------------------------\n",
    "    # Process polygons if available\n",
    "    # ----------------------------\n",
    "    if hasattr(result.masks, \"xy\") and result.masks.xy is not None:\n",
    "        for poly in result.masks.xy:\n",
    "            # poly.shape = [num_points, 2]\n",
    "            pts = [[float(x)/w, float(y)/h] for x, y in poly]  # normalize\n",
    "            polygons.append(fo.Polyline(points=[pts], label=DETECTION_LABEL))  # Keep [pts] wrapper\n",
    "    \n",
    "    # ----------------------------\n",
    "    # Save everything to the sample\n",
    "    # ----------------------------\n",
    "    # Primary detections\n",
    "    sample[PREDICTIONS_FIELD] = fo.Detections(detections=detections)\n",
    "    \n",
    "    # Additionally store polygons in a separate field, if present\n",
    "    if polygons:\n",
    "        sample[f\"{PREDICTIONS_FIELD}_polygons\"] = fo.Polylines(polylines=polygons)\n",
    "    \n",
    "    sample.save()\n",
    "\n",
    "print(f\"\\n‚úÖ Detection finished! Predictions saved to field '{PREDICTIONS_FIELD}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "PREDICTIONS_FIELD = 'SIMPLE_12'\n",
    "\n",
    "print(f\"Running detection on {len(test_view)} images...\")\n",
    "print(f\"Results will be stored in field: '{PREDICTIONS_FIELD}'\\n\")\n",
    "\n",
    "for i, sample in tqdm(enumerate(test_view), total=len(test_view)):\n",
    "    # if i % 10 == 0:\n",
    "    #     print(f\"Processed: {i}/{len(test_view)}\")\n",
    "    \n",
    "    # Run YOLO detection\n",
    "    results = model.predict(\n",
    "        source=sample.filepath,\n",
    "        conf=CONFIDENCE_THRESHOLD,\n",
    "        iou=IOU_THRESHOLD,\n",
    "        imgsz=IMG_SIZE,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    detections = []\n",
    "    polygons = []\n",
    "    img = cv2.imread(sample.filepath)\n",
    "    h, w = img.shape[:2]\n",
    "    \n",
    "    result = results[0]\n",
    "    \n",
    "    # ----------------------------\n",
    "    # Process bounding boxes\n",
    "    # ----------------------------\n",
    "    for box in result.boxes:\n",
    "        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "        conf = float(box.conf[0])\n",
    "        if conf < CONFIDENCE_THRESHOLD:\n",
    "            continue\n",
    "        cls = int(box.cls[0])\n",
    "        \n",
    "        det = fo.Detection(\n",
    "            label=DETECTION_LABEL,\n",
    "            bounding_box=[x1/w, y1/h, (x2-x1)/w, (y2-y1)/h],\n",
    "            confidence=conf\n",
    "        )\n",
    "        detections.append(det)\n",
    "    \n",
    "    # ----------------------------\n",
    "    # Process polygons if available\n",
    "    # ----------------------------\n",
    "    if hasattr(result.masks, \"xy\") and result.masks.xy is not None:\n",
    "        for poly in result.masks.xy:\n",
    "            # poly.shape = [num_points, 2]\n",
    "            pts = [[float(x)/w, float(y)/h] for x, y in poly]  # normalize\n",
    "            polygons.append(fo.Polyline(points=[pts], label=DETECTION_LABEL))  # Keep [pts] wrapper\n",
    "    \n",
    "    # ----------------------------\n",
    "    # Save everything to the sample\n",
    "    # ----------------------------\n",
    "    # Primary detections\n",
    "    sample[PREDICTIONS_FIELD] = fo.Detections(detections=detections)\n",
    "    \n",
    "    # Additionally store polygons in a separate field, if present\n",
    "    if polygons:\n",
    "        sample[f\"{PREDICTIONS_FIELD}_polygons\"] = fo.Polylines(polylines=polygons)\n",
    "    \n",
    "    sample.save()\n",
    "\n",
    "print(f\"\\n‚úÖ Detection finished! Predictions saved to field '{PREDICTIONS_FIELD}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Prediction Statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Collect statistics\n",
    "stats = []\n",
    "\n",
    "for sample in tqdm(dataset):\n",
    "    # Number of predictions\n",
    "    preds = sample[PREDICTIONS_FIELD]\n",
    "    num_preds = len(preds.detections) if preds else 0\n",
    "    \n",
    "    # Number of ground truth objects (from Polylines in the GT_FIELD)\n",
    "    gt = sample[GT_FIELD] if GT_FIELD in sample.field_names else None\n",
    "    num_gt = len(gt.polylines) if gt else 0\n",
    "    \n",
    "    # Average confidence\n",
    "    if preds and preds.detections:\n",
    "        confidences = [d.confidence for d in preds.detections]\n",
    "        avg_conf = np.mean(confidences)\n",
    "        max_conf = max(confidences)\n",
    "        min_conf = min(confidences)\n",
    "    else:\n",
    "        avg_conf = max_conf = min_conf = 0\n",
    "    \n",
    "    stats.append({\n",
    "        'Sample ID': sample.id[:8] + '...',\n",
    "        'Filename': Path(sample.filepath).name,\n",
    "        'Predictions': num_preds,\n",
    "        'Ground Truth': num_gt,\n",
    "        'Avg Conf': f\"{avg_conf:.3f}\",\n",
    "        'Max Conf': f\"{max_conf:.3f}\",\n",
    "        'Min Conf': f\"{min_conf:.3f}\"\n",
    "    })\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(stats)\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"üìä DETECTION STATISTICS\")\n",
    "print(\"=\"*100)\n",
    "print(df.head(20).to_string(index=False))\n",
    "print(\"\\n... (showing first 20 rows)\\n\")\n",
    "\n",
    "# Overall statistics\n",
    "total_preds = df['Predictions'].sum()\n",
    "total_gt = df['Ground Truth'].sum()\n",
    "avg_preds_per_img = df['Predictions'].mean()\n",
    "imgs_with_preds = len(df[df['Predictions'] > 0])\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"üìà OVERALL STATISTICS\")\n",
    "print(\"=\"*100)\n",
    "print(f\"Total images:                    {len(test_view)}\")\n",
    "print(f\"Images with predictions:         {imgs_with_preds} ({imgs_with_preds/len(test_view)*100:.1f}%)\")\n",
    "print(f\"Total predictions:               {total_preds}\")\n",
    "print(f\"Total ground truth:              {total_gt}\")\n",
    "print(f\"Average predictions per image:  {avg_preds_per_img:.2f}\")\n",
    "print(f\"Average GT per image:            {total_gt/len(test_view):.2f}\")\n",
    "print(\"=\"*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Evaluation and Validation\n",
    "\n",
    "We compute COCO-style metrics for the YOLO26 predictions using IoU thresholds 0.5 and 0.95, and store the results in the dataset for further analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GT_DETECTIONS_FIELD = \"gt_bodyshape_detections\"\n",
    "EVAL_KEY = ''\n",
    "COCO_IOU_THRESHOLDS = [0.5, 0.95]\n",
    "print(f\"EVAL_KEY: {EVAL_KEY}\")\n",
    "\n",
    "def _polylines_to_detections(polyline_field):\n",
    "    detections = []\n",
    "    if not polyline_field:\n",
    "        return detections\n",
    "\n",
    "    for polyline in polyline_field.polylines:\n",
    "        points = [pt for segment in polyline.points for pt in segment]\n",
    "        if not points:\n",
    "            continue\n",
    "\n",
    "        xs = [pt[0] for pt in points]\n",
    "        ys = [pt[1] for pt in points]\n",
    "        x_min, x_max = min(xs), max(xs)\n",
    "        y_min, y_max = min(ys), max(ys)\n",
    "\n",
    "        width = max(1e-6, min(1.0, x_max - x_min))\n",
    "        height = max(1e-6, min(1.0, y_max - y_min))\n",
    "        x_min = max(0.0, min(1.0, x_min))\n",
    "        y_min = max(0.0, min(1.0, y_min))\n",
    "\n",
    "        label = DETECTION_LABEL\n",
    "        detections.append(\n",
    "            fo.Detection(\n",
    "                label=\"Fish\",\n",
    "                bounding_box=[x_min, y_min, width, height],\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return detections\n",
    "\n",
    "\n",
    "if len(test_view) == 0:\n",
    "    print(\"‚ö†Ô∏è No test images available for evaluation\")\n",
    "else:\n",
    "    first_sample = dataset.first()\n",
    "    if first_sample is not None and GT_DETECTIONS_FIELD not in first_sample.field_names:\n",
    "        print(\"Creating a field with detected GT bboxes...\")\n",
    "        for sample in test_view:\n",
    "            gt_field = sample[GT_FIELD] if GT_FIELD in sample.field_names else None\n",
    "            sample[GT_DETECTIONS_FIELD] = fo.Detections(\n",
    "                detections=_polylines_to_detections(gt_field)\n",
    "            )\n",
    "            sample.save()\n",
    "        print(f\"‚úÖ Field '{GT_DETECTIONS_FIELD}' added for {len(test_view)} samples\")\n",
    "    elif first_sample is not None:\n",
    "        print(f\"Field '{GT_DETECTIONS_FIELD}' already exists, skipping transformation\")\n",
    "\n",
    "    print(\"\\nRunning COCO evaluation (compute_mAP + IoU sweep)\")\n",
    "    coco_results = test_view.evaluate_detections(\n",
    "        PREDICTIONS_FIELD,\n",
    "        gt_field=GT_DETECTIONS_FIELD,\n",
    "        eval_key=\"\",\n",
    "        method=\"coco\",\n",
    "        iou=0.5,\n",
    "        classwise=False,\n",
    "        compute_mAP=True,\n",
    "        iou_threshs=COCO_IOU_THRESHOLDS,\n",
    "        max_preds=500,\n",
    "    )\n",
    "\n",
    "    def _mean_positive(values):\n",
    "        arr = np.array(values, dtype=float)\n",
    "        valid = arr[arr > -1]\n",
    "        if valid.size == 0:\n",
    "            return float(\"nan\")\n",
    "        return float(valid.mean())\n",
    "\n",
    "    def _ap_at(iou_thresh):\n",
    "        idx = coco_results._get_iou_thresh_inds(iou_thresh)[0]\n",
    "        per_class_ap = np.mean(coco_results.precision[idx], axis=1)\n",
    "        return _mean_positive(per_class_ap)\n",
    "\n",
    "    def _ar_at(iou_thresh):\n",
    "        if coco_results.recall_sweep is None:\n",
    "            return float(\"nan\")\n",
    "        idx = coco_results._get_iou_thresh_inds(iou_thresh)[0]\n",
    "        per_class_ar = np.array(coco_results.recall_sweep[idx], dtype=float)\n",
    "        return _mean_positive(per_class_ar)\n",
    "\n",
    "    tp_total = sum(value or 0 for value in test_view.values(f\"{EVAL_KEY}_tp\"))\n",
    "    fp_total = sum(value or 0 for value in test_view.values(f\"{EVAL_KEY}_fp\"))\n",
    "    fn_total = sum(value or 0 for value in test_view.values(f\"{EVAL_KEY}_fn\"))\n",
    "\n",
    "    classification_metrics = coco_results.metrics()\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 90)\n",
    "    print(\"üßÆ COCO-style metrics\")\n",
    "    print(\"=\" * 90)\n",
    "    print(f\"mAP (IoU 0.5:0.95):          {coco_results.mAP():.3f}\")\n",
    "    print(f\"mAR (IoU 0.5:0.95):          {coco_results.mAR():.3f}\")\n",
    "    print(f\"AP @ 0.5:                    {_ap_at(0.5):.3f}\")\n",
    "    print(f\"AP @ 0.95:                   {_ap_at(0.95):.3f}\")\n",
    "    print(f\"AR @ 0.5:                    {_ar_at(0.5):.3f}\")\n",
    "    print(f\"AR @ 0.95:                   {_ar_at(0.95):.3f}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 90)\n",
    "    print(\"‚öñÔ∏è Classification metrics\")\n",
    "    print(\"=\" * 90)\n",
    "    print(f\"Precision (micro):            {classification_metrics['precision']:.3f}\")\n",
    "    print(f\"Recall (micro):               {classification_metrics['recall']:.3f}\")\n",
    "    print(f\"F1-score (micro):             {classification_metrics['fscore']:.3f}\")\n",
    "    print(f\"Accuracy:                     {classification_metrics['accuracy']:.3f}\")\n",
    "    print(f\"Support:                      {classification_metrics['support']}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 90)\n",
    "    print(\"üî¢ TP/FP/FN counters / objects\")\n",
    "    print(\"=\" * 90)\n",
    "    print(f\"TP: {tp_total}, FP: {fp_total}, FN: {fn_total}\")\n",
    "    print(f\"Total GT objects:            {total_gt}\")\n",
    "    print(f\"Total predictions:           {total_preds}\")\n",
    "    print(\"=\" * 90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GT_DETECTIONS_FIELD = \"sam3_segmentation_rect\"\n",
    "EVAL_KEY = ''\n",
    "COCO_IOU_THRESHOLDS = [0.5, 0.95]\n",
    "print(f\"EVAL_KEY: {EVAL_KEY}\")\n",
    "GT_FIELD = 'sam3_segmentation'\n",
    "\n",
    "print(\"Creating a field with detected GT bboxes...\")\n",
    "for sample in tqdm(test_view):\n",
    "    gt_field = sample[GT_FIELD] if GT_FIELD in sample.field_names else None\n",
    "    sample[GT_DETECTIONS_FIELD] = fo.Detections(\n",
    "        detections=_polylines_to_detections(gt_field)\n",
    "    )\n",
    "    sample.save()\n",
    "print(f\"‚úÖ Field '{GT_DETECTIONS_FIELD}' added for {len(test_view)} samples\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. FiftyOne App Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTIONS_FIELD = ''\n",
    "GT_DETECTIONS_FIELD = 'sam3_segmentation_rect'\n",
    "print(\"\\nRunning COCO evaluation (compute_mAP + IoU sweep)\")\n",
    "coco_results = test_view.evaluate_detections(\n",
    "    PREDICTIONS_FIELD,\n",
    "    gt_field=GT_DETECTIONS_FIELD,\n",
    "    eval_key=None,\n",
    "    method=\"coco\",\n",
    "    iou=0.5,\n",
    "    classwise=True,\n",
    "    compute_mAP=True,\n",
    "    iou_threshs=np.arange(0.5, 0.96, 0.05),\n",
    "    max_preds=500,\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 90)\n",
    "print(\"üßÆ COCO-style metrics\")\n",
    "print(\"=\" * 90)\n",
    "print(f\"mAP (IoU 0.5:0.95):          {coco_results.mAP():.3f}\")\n",
    "print(f\"mAR (IoU 0.5:0.95):          {coco_results.mAR():.3f}\")\n",
    "print(f\"AP @ 0.5:                    {_ap_at(0.5):.3f}\")\n",
    "print(f\"AP @ 0.95:                   {_ap_at(0.95):.3f}\")\n",
    "print(f\"AR @ 0.5:                    {_ar_at(0.5):.3f}\")\n",
    "print(f\"AR @ 0.95:                   {_ar_at(0.95):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_thresholds = np.arange(0.1, 1.0, 0.05)\n",
    "best_mAP = 0\n",
    "best_thr = 0\n",
    "for thr in conf_thresholds:\n",
    "    coco_results = test_view.evaluate_detections(\n",
    "        \"\",\n",
    "        gt_field=\"sam3_segmentation_rect\",\n",
    "        method=\"coco\",\n",
    "        iou=0.5,\n",
    "        classwise=True,\n",
    "        compute_mAP=True,\n",
    "        max_preds=500,\n",
    "        conf_threshold=thr  # <-- set the threshold here\n",
    "    )\n",
    "    mAP = coco_results.mAP()\n",
    "    print(f\"Current conf threshold: {best_thr}, mAP={best_mAP:.3f}\")\n",
    "    if mAP > best_mAP:\n",
    "        best_mAP = mAP\n",
    "        best_thr = thr\n",
    "        print(f\"Best conf threshold: {best_thr}, mAP={best_mAP:.3f}\")\n",
    "\n",
    "print(f\"Best conf threshold: {best_thr}, mAP={best_mAP:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_results.print_report(classes=['Fish'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V09\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        Fish       0.98      0.70      0.81     83223\n",
    "\n",
    "   micro avg       0.98      0.70      0.81     83223\n",
    "   macro avg       0.98      0.70      0.81     83223\n",
    "weighted avg       0.98      0.70      0.81     83223\n",
    "\n",
    "fish_detection_20260203_130548\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        Fish       0.94      0.79      0.86     83223\n",
    "\n",
    "   micro avg       0.94      0.79      0.86     83223\n",
    "   macro avg       0.94      0.79      0.86     83223\n",
    "weighted avg       0.94      0.79      0.86     83223\n",
    "\n",
    "yolo26_v10_run_5_best\n",
    "            precision    recall  f1-score   support\n",
    "\n",
    "        Fish       0.97      0.69      0.80     83223\n",
    "\n",
    "   micro avg       0.97      0.69      0.80     83223\n",
    "   macro avg       0.97      0.69      0.80     83223\n",
    "weighted avg       0.97      0.69      0.80     83223\n",
    "\n",
    "fish_detection_20260204_115831\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        Fish       0.94      0.80      0.86     83223\n",
    "\n",
    "   micro avg       0.94      0.80      0.86     83223\n",
    "   macro avg       0.94      0.80      0.86     83223\n",
    "weighted avg       0.94      0.80      0.86     83223\n",
    "\n",
    "fish_detection_20260205_211724\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        Fish       0.94      0.79      0.86     83223\n",
    "\n",
    "   micro avg       0.94      0.79      0.86     83223\n",
    "   macro avg       0.94      0.79      0.86     83223\n",
    "weighted avg       0.94      0.79      0.86     83223\n",
    "\n",
    "SAMPLE 12\n",
    "                 precision    recall  f1-score   support\n",
    "\n",
    "        Fish       0.94      0.78      0.85     83223\n",
    "\n",
    "   micro avg       0.94      0.78      0.85     83223\n",
    "   macro avg       0.94      0.78      0.85     83223\n",
    "weighted avg       0.94      0.78      0.85     83223\n",
    "\n",
    "\n",
    "SAMPLE MEDIUM 2 Update 16/02\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        Fish       0.94      0.86      0.90     83223\n",
    "\n",
    "   micro avg       0.94      0.86      0.90     83223\n",
    "   macro avg       0.94      0.86      0.90     83223\n",
    "weighted avg       0.94      0.86      0.90     83223\n",
    "\n",
    "SAMPLE_MEDIUM2 TEST Dataset\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        Fish       0.89      1.00      0.94     20849\n",
    "\n",
    "   micro avg       0.89      1.00      0.94     20849\n",
    "   macro avg       0.89      1.00      0.94     20849\n",
    "weighted avg       0.89      1.00      0.94     20849\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
